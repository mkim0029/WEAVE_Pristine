{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8bc7a95",
   "metadata": {},
   "source": [
    "# Performance Analysis: local_asymmetric_sigclip Function\n",
    "\n",
    "This notebook analyzes the performance bottlenecks in the `local_asymmetric_sigclip` function to understand why the optimization didn't provide the expected speedup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211aef32",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import necessary libraries for performance analysis including time, cProfile, memory_profiler, and any relevant modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cfe42cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import cProfile\n",
    "import pstats\n",
    "from io import StringIO\n",
    "from astropy.stats import sigma_clip\n",
    "\n",
    "# Import your continuum normalization module\n",
    "from cont_norm import local_asymmetric_sigclip\n",
    "\n",
    "# For memory profiling (install with: pip install memory_profiler)\n",
    "# %load_ext memory_profiler\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a81fdaf",
   "metadata": {},
   "source": [
    "## Create Test Data\n",
    "\n",
    "Generate synthetic spectrum data similar to your real data to isolate performance issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcb7358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum_index = 0  # Change this index to plot a different spectrum\n",
    "from hdf5_spectrum_reader import HDF5SpectrumReader\n",
    "\n",
    "# Load the spectrum data\n",
    "spectrum_file = \"../data/weave_nlte_grids.h5\"\n",
    "reader = HDF5SpectrumReader(spectrum_file)\n",
    "\n",
    "wavelength, flux = reader.get_wavelength_flux(spectrum_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8193ebf1",
   "metadata": {},
   "source": [
    "## 2. Measure Execution Time with %timeit\n",
    "\n",
    "Use Jupyter's %timeit magic command to get accurate timing measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d0ffc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing local_asymmetric_sigclip performance...\n",
      "3min 2s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Test with your original function\n",
    "print(\"Testing local_asymmetric_sigclip performance...\")\n",
    "%timeit -n 1 -r 1 result = local_asymmetric_sigclip(flux, wavelength, window_width=10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e04287",
   "metadata": {},
   "source": [
    "## 3. Profile Code with %prun\n",
    "\n",
    "Use %prun magic command to identify which functions and lines of code are consuming the most time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38abf71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "text/plain": [
       "         206446619 function calls (205164932 primitive calls) in 251.698 seconds\n",
       "\n",
       "   Ordered by: internal time\n",
       "   List reduced from 113 to 20 due to restriction <20>\n",
       "\n",
       "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
       "  1281687   28.063    0.000  113.586    0.000 nanfunctions.py:1617(nanvar)\n",
       "  8119990   20.035    0.000   20.035    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
       "  2563374   16.342    0.000   38.703    0.000 nanfunctions.py:187(_divide_by_count)\n",
       "   107467   15.595    0.000  237.255    0.002 sigma_clipping.py:429(_sigmaclip_noaxis)\n",
       "  1389154    9.663    0.000   18.766    0.000 _methods.py:101(_mean)\n",
       "  1389154    9.382    0.000   58.932    0.000 function_base.py:3931(_median)\n",
       "  1389154    9.380    0.000    9.380    0.000 {method 'partition' of 'numpy.ndarray' objects}\n",
       "  1281687    8.826    0.000  214.376    0.000 sigma_clipping.py:313(_compute_bounds)\n",
       "  5341682    8.295    0.000   18.159    0.000 _ufunc_config.py:33(seterr)\n",
       "  5234215    8.037    0.000   26.885    0.000 fromnumeric.py:71(_wrapreduction)\n",
       "  1281687    6.720    0.000    8.544    0.000 nanfunctions.py:68(_replace_nan)\n",
       "  5341682    6.578    0.000    7.101    0.000 _ufunc_config.py:132(geterr)\n",
       "   214934    5.370    0.000    5.370    0.000 {method 'searchsorted' of 'numpy.ndarray' objects}\n",
       "2670841/1389154    5.363    0.000   76.986    0.000 function_base.py:3763(_ureduce)\n",
       "  1281687    5.343    0.000  119.629    0.000 nanfunctions.py:1778(nanstd)\n",
       "  3845061    4.624    0.000   23.494    0.000 fromnumeric.py:2177(sum)\n",
       "  1389154    4.079    0.000   11.627    0.000 utils.py:1081(_median_nancheck)\n",
       "  1281687    3.703    0.000    6.898    0.000 nanfunctions.py:142(_remove_nan_1d)\n",
       "  1281687    3.693    0.000    4.072    0.000 nanfunctions.py:113(_copyto)\n",
       "  1389154    3.348    0.000    3.889    0.000 _methods.py:67(_count_reduce_items)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Profile the function to see where time is spent\n",
    "%prun -l 20 result = local_asymmetric_sigclip(flux, wavelength, window_width=10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9991559",
   "metadata": {},
   "source": [
    "## 4. Detailed Component Analysis\n",
    "\n",
    "Let's analyze each component of the function separately to identify the bottleneck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "395a71ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing searchsorted performance...\n",
      "Searchsorted time for 50000 iterations: 5.57 seconds\n",
      "\n",
      "Testing sigma_clip performance...\n",
      "Typical window size: 912 points\n",
      "Sigma clipping time for 1000 samples: 1.48 seconds\n",
      "Estimated sigma clipping time for 50000 iterations: 74.20 seconds\n"
     ]
    }
   ],
   "source": [
    "# Test individual components to identify the bottleneck\n",
    "def test_searchsorted_performance():\n",
    "    \"\"\"Test just the window finding part\"\"\"\n",
    "    n = len(flux)\n",
    "    times = []\n",
    "    \n",
    "    start = time.time()\n",
    "    for i in range(n):\n",
    "        wl_center = wavelength[i]\n",
    "        wl_min = wl_center - 5.0  # 10 Å window\n",
    "        wl_max = wl_center + 5.0\n",
    "        \n",
    "        left_idx = np.searchsorted(wavelength, wl_min, side='left')\n",
    "        right_idx = np.searchsorted(wavelength, wl_max, side='right')\n",
    "    \n",
    "    end = time.time()\n",
    "    return end - start\n",
    "\n",
    "def test_sigma_clip_performance():\n",
    "    \"\"\"Test sigma clipping on typical window sizes\"\"\"\n",
    "    # Typical window size in your spectra\n",
    "    typical_window_size = int(10 * n_points / (wavelength.max() - wavelength.min()))\n",
    "    print(f\"Typical window size: {typical_window_size} points\")\n",
    "    \n",
    "    # Sample some windows\n",
    "    n_samples = 1000\n",
    "    times = []\n",
    "    \n",
    "    start = time.time()\n",
    "    for i in range(n_samples):\n",
    "        start_idx = np.random.randint(0, n_points - typical_window_size)\n",
    "        window_flux = flux[start_idx:start_idx + typical_window_size]\n",
    "        \n",
    "        res = sigma_clip(window_flux, sigma_lower=0.5, sigma_upper=2.0, maxiters=None)\n",
    "        clip_vals = res.compressed()\n",
    "        if clip_vals.size > 0:\n",
    "            loc = np.median(clip_vals)\n",
    "        else:\n",
    "            loc = np.median(window_flux)\n",
    "    \n",
    "    end = time.time()\n",
    "    return end - start\n",
    "\n",
    "# Run component tests\n",
    "print(\"Testing searchsorted performance...\")\n",
    "searchsorted_time = test_searchsorted_performance()\n",
    "print(f\"Searchsorted time for {n_points} iterations: {searchsorted_time:.2f} seconds\")\n",
    "\n",
    "print(\"\\nTesting sigma_clip performance...\")\n",
    "sigclip_time = test_sigma_clip_performance()\n",
    "print(f\"Sigma clipping time for 1000 samples: {sigclip_time:.2f} seconds\")\n",
    "print(f\"Estimated sigma clipping time for {n_points} iterations: {sigclip_time * n_points / 1000:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a33a58",
   "metadata": {},
   "source": [
    "## 5. Alternative Optimization Approaches\n",
    "\n",
    "Based on the bottleneck analysis, let's implement more aggressive optimizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfa06709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized functions defined!\n"
     ]
    }
   ],
   "source": [
    "def local_asymmetric_sigclip_optimized_v2(flux, wavelength, window_width=10.0, sigma_lower=0.5, sigma_upper=2.0):\n",
    "    \"\"\"\n",
    "    Heavily optimized version with reduced sigma_clip calls and vectorization where possible.\n",
    "    \"\"\"\n",
    "    flux = np.asarray(flux)\n",
    "    wavelength = np.asarray(wavelength)\n",
    "    n = len(flux)\n",
    "    norm = np.empty_like(flux)\n",
    "    \n",
    "    # Pre-compute window size in pixels (approximate)\n",
    "    delta_wl = np.median(np.diff(wavelength))\n",
    "    window_pixels = int(window_width / delta_wl)\n",
    "    \n",
    "    # Use a simpler sliding window approach with fixed pixel window\n",
    "    for i in range(n):\n",
    "        # Use fixed pixel window centered on current point\n",
    "        left_idx = max(0, i - window_pixels // 2)\n",
    "        right_idx = min(n, i + window_pixels // 2 + 1)\n",
    "        \n",
    "        window_flux = flux[left_idx:right_idx]\n",
    "        \n",
    "        if window_flux.size == 0:\n",
    "            norm[i] = flux[i]\n",
    "            continue\n",
    "            \n",
    "        # Quick outlier rejection without full sigma_clip\n",
    "        # Use percentile-based clipping instead\n",
    "        if window_flux.size > 5:  # Only if we have enough points\n",
    "            p_low = np.percentile(window_flux, 15.87)  # ~1 sigma below\n",
    "            p_high = np.percentile(window_flux, 84.13)  # ~1 sigma above\n",
    "            \n",
    "            # Apply asymmetric clipping\n",
    "            mask_low = window_flux >= (np.median(window_flux) - sigma_lower * (np.median(window_flux) - p_low))\n",
    "            mask_high = window_flux <= (np.median(window_flux) + sigma_upper * (p_high - np.median(window_flux)))\n",
    "            \n",
    "            clipped_flux = window_flux[mask_low & mask_high]\n",
    "            \n",
    "            if clipped_flux.size > 0:\n",
    "                loc = np.median(clipped_flux)\n",
    "            else:\n",
    "                loc = np.median(window_flux)\n",
    "        else:\n",
    "            loc = np.median(window_flux)\n",
    "            \n",
    "        norm[i] = flux[i] / loc if loc != 0 else flux[i]\n",
    "    \n",
    "    return norm\n",
    "\n",
    "def local_asymmetric_sigclip_super_fast(flux, wavelength, window_width=10.0, sigma_lower=0.5, sigma_upper=2.0, stride=10):\n",
    "    \"\"\"\n",
    "    Ultra-fast version: compute continuum at sparse grid points and interpolate.\n",
    "    \"\"\"\n",
    "    flux = np.asarray(flux)\n",
    "    wavelength = np.asarray(wavelength)\n",
    "    n = len(flux)\n",
    "    \n",
    "    # Compute continuum estimates at every 'stride' points\n",
    "    sparse_indices = np.arange(0, n, stride)\n",
    "    sparse_continuum = np.empty(len(sparse_indices))\n",
    "    \n",
    "    delta_wl = np.median(np.diff(wavelength))\n",
    "    window_pixels = int(window_width / delta_wl)\n",
    "    \n",
    "    for j, i in enumerate(sparse_indices):\n",
    "        left_idx = max(0, i - window_pixels // 2)\n",
    "        right_idx = min(n, i + window_pixels // 2 + 1)\n",
    "        \n",
    "        window_flux = flux[left_idx:right_idx]\n",
    "        \n",
    "        # Simple robust estimator\n",
    "        if window_flux.size > 3:\n",
    "            sorted_flux = np.sort(window_flux)\n",
    "            # Use interquartile range for robust estimate\n",
    "            q1_idx = len(sorted_flux) // 4\n",
    "            q3_idx = 3 * len(sorted_flux) // 4\n",
    "            sparse_continuum[j] = np.mean(sorted_flux[q1_idx:q3_idx])\n",
    "        else:\n",
    "            sparse_continuum[j] = np.median(window_flux) if window_flux.size > 0 else flux[i]\n",
    "    \n",
    "    # Interpolate continuum to all points\n",
    "    continuum = np.interp(np.arange(n), sparse_indices, sparse_continuum)\n",
    "    \n",
    "    # Normalize\n",
    "    continuum = np.where(continuum == 0, 1, continuum)\n",
    "    norm = flux / continuum\n",
    "    \n",
    "    return norm\n",
    "\n",
    "print(\"Optimized functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801bfd19",
   "metadata": {},
   "source": [
    "## 6. Compare Performance of Different Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2de0018c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Comparison:\n",
      "==================================================\n",
      "\n",
      "2. V2 Optimized (percentile-based clipping):\n",
      "40.6 s ± 54.2 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
      "\n",
      "3. Super Fast (sparse grid + interpolation):\n",
      "169 ms ± 799 µs per loop (mean ± std. dev. of 5 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Compare performance of different approaches\n",
    "print(\"Performance Comparison:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "#print(\"\\n1. Original optimized function (searchsorted):\")\n",
    "#%timeit -n 1 -r 1 result1 = local_asymmetric_sigclip(flux, wavelength, window_width=10.0)\n",
    "\n",
    "print(\"\\n2. V2 Optimized (percentile-based clipping):\")\n",
    "%timeit -n 1 -r 3 result2 = local_asymmetric_sigclip_optimized_v2(flux, wavelength, window_width=10.0)\n",
    "\n",
    "print(\"\\n3. Super Fast (sparse grid + interpolation):\")\n",
    "%timeit -n 1 -r 5 result3 = local_asymmetric_sigclip_super_fast(flux, wavelength, window_width=10.0, stride=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6daa85",
   "metadata": {},
   "source": [
    "## Key Insights and Recommendations\n",
    "\n",
    "Based on the profiling results, the main bottleneck is likely the **sigma_clip function** being called 50,000 times (once per pixel). Each call to `sigma_clip` has significant overhead even for small arrays.\n",
    "\n",
    "**The real performance killer is:**\n",
    "1. **Function call overhead**: `sigma_clip` is called n times\n",
    "2. **Statistical computation overhead**: Mean, std calculation for each small window  \n",
    "3. **Masking operations**: Creating and applying masks for each window\n",
    "\n",
    "**Solutions to try:**\n",
    "1. Replace `sigma_clip` with simple percentile-based outlier rejection\n",
    "2. Use sparse sampling + interpolation for massive speedup\n",
    "3. Consider chunked processing or parallel processing\n",
    "4. Pre-compute statistics where possible\n",
    "\n",
    "Run this notebook with your actual data to see which approach works best for your use case!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
